import streamlit as st
import google.generativeai as genai
import json
import os
import pypdf

# Configuraci√≥n b√°sica
st.set_page_config(page_title="Motor Cr√≠tico", layout="wide", page_icon="üõ°Ô∏è")

# Estilos CSS
st.markdown("""
<style>
    div[data-testid="stMetricValue"] { font-size: 30px; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# API KEY
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except:
    st.error("‚ö†Ô∏è ERROR: No se detect√≥ la API KEY en los Secrets.")
    st.stop()

# Lectura de PDFs
@st.cache_resource
def cargar_biblioteca_desde_pdfs(carpeta="datos"):
    texto_total = ""
    archivos_leidos = []
    if not os.path.exists(carpeta):
        return "ADVERTENCIA: Carpeta 'datos' no encontrada.", []
    
    archivos = [f for f in os.listdir(carpeta) if f.endswith('.pdf')]
    for archivo in archivos:
        try:
            ruta_pdf = os.path.join(carpeta, archivo)
            reader = pypdf.PdfReader(ruta_pdf)
            for page in reader.pages:
                texto_total += page.extract_text() + "\n"
            texto_total += f"\n--- FIN DOCUMENTO: {archivo} ---\n"
            archivos_leidos.append(archivo)
        except:
            pass 
    return texto_total, archivos_leidos

BIBLIOTECA_CONOCIMIENTO, LISTA_ARCHIVOS = cargar_biblioteca_desde_pdfs()

# --- CONFIGURACI√ìN GANADORA ---
# Usamos el nombre que sabemos que funciona en tu servidor:
MODEL_NAME = "models/gemini-flash-latest"

SYSTEM_INSTRUCTION = f"""
Eres el "Motor de Desarticulaci√≥n L√≥gica". 
Tu tarea es analizar argumentos sobre IA bas√°ndote en estos documentos: {LISTA_ARCHIVOS}.

Debes responder SIEMPRE con este esquema JSON exacto (sin markdown extra):
{{
  "Clasificacion": "GRUPO A (T√©cnico) o GRUPO B (Cultural)",
  "Nivel_Alarmismo": (N√∫mero entero 0-100),
  "Punto_de_Dolor": "Texto breve...",
  "Riesgo_Real": "Texto breve...",
  "Desarticulacion": "Texto breve...",
  "Cita": "Cita textual breve...",
  "Autor_Cita": "Nombre del archivo fuente"
}}

CONTEXTO DOCUMENTAL:
{BIBLIOTECA_CONOCIMIENTO}
"""

generation_config = {
    "temperature": 0.5,
    "max_output_tokens": 8192,
    "response_mime_type": "application/json", # Forzamos respuesta limpia
}

model = genai.GenerativeModel(
    model_name=MODEL_NAME,
    generation_config=generation_config,
    system_instruction=SYSTEM_INSTRUCTION
)

# Interfaz
with st.sidebar:
    st.title("üéõÔ∏è Panel de Control")
    if len(LISTA_ARCHIVOS) > 0:
        st.success(f"‚úÖ **Sistema Online**\nConectado a {len(LISTA_ARCHIVOS)} fuentes.")
    else:
        st.error("‚ö†Ô∏è Sin documentos.")
    st.markdown("---")
    modo = st.radio("Modo:", ["‚úçÔ∏è Escribir cr√≠tica", "üìÇ Casos predefinidos"])

st.title("üõ°Ô∏è Motor Cr√≠tico")

if modo == "‚úçÔ∏è Escribir cr√≠tica":
    input_usuario = st.text_area("Argumento a analizar:", height=100)
else:
    # RECUPERAMOS LA LISTA ESTRAT√âGICA COMPLETA
    input_usuario = st.selectbox("Selecciona un caso t√≠pico para analizar:", [
        "La IA es una caja negra que tomar√° decisiones de vida o muerte sin que sepamos por qu√©.",
        "La IA roba el alma de los artistas al copiar sus estilos y anula la creatividad humana.",
        "Los robots nos quitar√°n el trabajo y viviremos en la miseria absoluta.",
        "Siento que las aplicaciones me escuchan y vigilan para manipular lo que compro y pienso.",
        "Si un coche aut√≥nomo atropella a alguien por error, la culpa es del algoritmo, no de las personas.",
        "Nos estamos convirtiendo en simples datos para alimentar a la m√°quina y perdiendo nuestra esencia biol√≥gica."
    ])
if st.button("üîç EJECUTAR AN√ÅLISIS", type="primary"):
    if not input_usuario:
        st.warning("El campo est√° vac√≠o.")
    else:
        with st.spinner('Procesando...'):
            try:
                response = model.generate_content(input_usuario)
                
                # Limpieza extra por seguridad
                texto_limpio = response.text.replace("```json", "").replace("```", "").strip()
                data = json.loads(texto_limpio)
                
                # Visualizaci√≥n
                alarmismo = data.get('Nivel_Alarmismo', 0)
                
                st.markdown("### üìä Diagn√≥stico")
                c1, c2 = st.columns([1, 3])
                with c1:
                    st.metric("Alarmismo", f"{alarmismo}%")
                with c2:
                    st.progress(alarmismo / 100)
                    st.caption(f"Perfil: {data.get('Clasificacion')}")

                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                col1.error(f"**Dolor:**\n{data.get('Punto_de_Dolor')}")
                col2.warning(f"**Riesgo:**\n{data.get('Riesgo_Real')}")
                col3.success(f"**L√≥gica:**\n{data.get('Desarticulacion')}")

                with st.expander("üìö EVIDENCIA", expanded=True):
                    st.info(f'"{data.get("Cita")}"')
                    st.caption(f"üìç Fuente: {data.get('Autor_Cita')}")

            except Exception as e:
                st.error("Error analizando.")
                st.write(e)
                if 'response' in locals(): st.write("Respuesta cruda:", response.text)